{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ccd7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.prompts.prompts import SimpleInputPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07068de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "Doc ID: 790d40a5-36af-47c7-8251-a1a07c19edf0\n",
      "Text: Published as a conference paper at ICLR 2023 REAC T: S\n",
      "YNERGIZING REASONING AND ACTING IN LANGUAGE MODELS Shunyu Yao∗*,1,\n",
      "Jeffrey Zhao2, Dian Yu2, Nan Du2, Izhak Shafran2, Karthik Narasimhan1,\n",
      "Yuan Cao2 1Department of Computer Science, Princeton University\n",
      "2Google Research, Brain team 1{shunyuy,karthikn}@princeton.edu\n",
      "2{jeffreyzhao,dianyu,dunan,...\n"
     ]
    }
   ],
   "source": [
    "documents= SimpleDirectoryReader(\"data\").load_data()\n",
    "print(len(documents))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "582ad4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\" \n",
    "You are a knowledgeable and smart Q&A assistant.\n",
    "\n",
    "Your goals:\n",
    "- Use the provided context or retrieved documents to give accurate and relevant answers.\n",
    "- If the context doesn’t contain the exact answer, say you don’t have enough information instead of guessing.\n",
    "- Always summarize clearly and concisely.\n",
    "- When possible, provide structured and easy-to-read responses (use bullet points or short paragraphs).\n",
    "- Do not include unrelated or speculative content.\n",
    "- If the user’s question is ambiguous, politely ask for clarification.\n",
    "- Maintain a professional yet approachable tone.\n",
    "\n",
    "Example style:\n",
    "User: \"What is LlamaIndex?\"\n",
    "Assistant: \"LlamaIndex is a data framework that helps you connect external data (like files, databases, or APIs) to large language models. It simplifies loading, indexing, and querying data.\"\n",
    "\n",
    "You always follow these principles for every response.\n",
    "\"\"\"\n",
    "\n",
    "# default format supportable by llama2\n",
    "query_wrapper_prompt = SimpleInputPrompt(f\"<|USER|>{system_prompt}<|ASSISTANT|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e070460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "from typing import List, Optional\n",
    "HF_TOKEN: Optional[str] = os.getenv(\"HUGGINGFACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34b175",
   "metadata": {},
   "source": [
    "### **Now we set the settings for entire system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef2125f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 14:51:11,191 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = HuggingFaceInferenceAPI(\n",
    "    model_name=\"deepseek-ai/DeepSeek-V3.1\",\n",
    "    token=HF_TOKEN,\n",
    "    provider=\"together\",  # this will use the best provider available\n",
    ")\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
    "Settings.context_window = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1626dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 64/64 [00:00<00:00, 936.31it/s]\n",
      "Generating embeddings: 100%|██████████| 163/163 [00:00<00:00, 196.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# a vector store index only needs an embed model\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, embed_model=Settings.embed_model, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99f4c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from banks import Prompt\n",
    "from prompt_toolkit import prompt\n",
    "\n",
    "\n",
    "query_engine=index.as_query_engine(\n",
    "    Prompt=query_wrapper_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0bbb2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO is a real-time object detection system that processes streaming video with low latency, under 25 milliseconds. It analyzes entire images at once during both training and testing, enabling it to capture contextual information and reduce errors compared to methods like Fast R-CNN. YOLO is highly generalizable, performing well even on new or unexpected inputs such as artwork. However, it may struggle with precisely locating small objects. The system uses a grid-based approach to predict bounding boxes and confidence scores for objects in an image, supporting end-to-end training and open-source availability.\n"
     ]
    }
   ],
   "source": [
    "result = query_engine.query(\"What is YOLO?\")\n",
    "print(result.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
